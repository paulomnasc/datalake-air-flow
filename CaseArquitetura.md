## ğŸ§­ Arquitetura de Pipeline de Dados

Este projeto implementa uma arquitetura de ingestÃ£o e transformaÃ§Ã£o de dados com trÃªs zonas principais:

### ğŸ”¹ 1. **Raw Zone** (`lab01/processed/raw`)
- **Fonte:** Banco de dados MySQL local
- **Processo:** Dados sÃ£o extraÃ­dos e armazenados em formato bruto (ex: JSON ou CSV) no MinIO
- **Objetivo:** Preservar os dados originais para auditoria e reprocessamento

### ğŸ”¹ 2. **Trusted Zone** (`lab01/processed/trusted`)
- **Processo:** Os dados da raw zone sÃ£o validados, limpos e transformados
- **Formato:** PersistÃªncia em arquivos **Parquet**, otimizados para leitura analÃ­tica
- **Objetivo:** Garantir qualidade e estrutura dos dados para consumo confiÃ¡vel

### ğŸ”¹ 3. **Refined Zone** (PostgreSQL)
- **Processo:** Os dados da trusted zone sÃ£o carregados no PostgreSQL
- **Modelo:** Estrutura de **datamart analÃ­tico**, com tabelas fato e dimensÃ£o
- **Objetivo:** Disponibilizar os dados para BI, dashboards e anÃ¡lises avanÃ§adas

---

## ğŸ”„ Fluxo da Pipeline

```plaintext
[MySQL local]
      â”‚
      â–¼
[Airflow DAG: ingestÃ£o]
â†’ Salva em MinIO (raw zone)
      â”‚
      â–¼
[Airflow DAG: validaÃ§Ã£o + transformaÃ§Ã£o]
â†’ Converte para Parquet (trusted zone)
      â”‚
      â–¼
[Airflow DAG: carga analÃ­tica]
â†’ Insere no PostgreSQL (refined zone)
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Componente     | FunÃ§Ã£o                                      |
|----------------|---------------------------------------------|
| **Airflow**    | OrquestraÃ§Ã£o das DAGs                       |
| **MinIO**      | Armazenamento de objetos (raw/trusted)      |
| **MySQL**      | Fonte de dados local                        |
| **PostgreSQL** | Camada analÃ­tica (refined zone)             |
| **Pandas**     | TransformaÃ§Ãµes e conversÃ£o para Parquet     |
| **SQLAlchemy** | IntegraÃ§Ã£o com PostgreSQL                   |

---

## ğŸ§  BenefÃ­cios da Arquitetura

- SeparaÃ§Ã£o clara entre dados brutos, confiÃ¡veis e analÃ­ticos
- Versionamento e rastreabilidade dos dados
- OtimizaÃ§Ã£o de leitura com Parquet
- Facilidade de integraÃ§Ã£o com ferramentas de BI e ML
